{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b402e334-0851-4ceb-8638-f6e48cd35f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cached scripts?\n",
    "load_aunle = True\n",
    "load_sunle = True\n",
    "save_res = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f40593-6d64-48c2-a26d-2aabfd86e2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments_utils.fetching import ResultsManager\n",
    "from sbibm import get_results\n",
    "\n",
    "import pandas as pd\n",
    "import jax.numpy as jnp\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0826384-26c4-4df4-966a-d0a8f5de5847",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations_str_map = {\"10⁵\": 100000, \"10⁴\": 10000, \"10³\": 1000}\n",
    "sbibm_results = get_results()\n",
    "sbibm_results['num_rounds'] = [10 if m in (\"SNRE\", \"SNPE\", \"SNLE\") else 1 for m in sbibm_results.algorithm.values]\n",
    "sbr = sbibm_results[[ \"task\", \"num_simulations\", \"num_observation\", \"algorithm\", \"RT\",]].copy()\n",
    "sbr['num_simulations']  =  [num_simulations_str_map[v] for v in sbr.num_simulations.values]\n",
    "sbr = sbr.set_index([ \"task\", \"num_simulations\", \"num_observation\", \"algorithm\",])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566616da-871f-4c11-86f9-e95874616ae8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SUNLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5690d00a-6945-420e-b1e8-b5fb5d0df5ca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_sunle:\n",
    "    with open(\"df_sunle_cached.pkl\", \"rb\") as f:\n",
    "        df_sunle_eval = pickle.load(f)\n",
    "    with open(\"df_time_sunle_cached.pkl\", \"rb\") as f:\n",
    "        df_sunle_time = pickle.load(f)\n",
    "else:\n",
    "    r = ResultsManager(\"icml\")\n",
    "    \n",
    "    # PERFORMANCE\n",
    "    rs = []\n",
    "    for t in (\"lotka_volterra\", \"slcp\", \"gaussian_linear_uniform\", \"two_moons\"):\n",
    "        print(t)\n",
    "        eval_result = r.fetch_evaluation_results(\n",
    "            experience_name=\"sunle\",\n",
    "            task=t\n",
    "        )\n",
    "        rs.append(eval_result)\n",
    "    df_sunle_eval = pd.concat(rs)\n",
    "    if save_res:\n",
    "        with open(\"df_sunle_cached.pkl\", \"wb\") as f:\n",
    "            pickle.dump(df_sunle_eval, f)\n",
    "            \n",
    "    # TIME\n",
    "    rs = {}\n",
    "    for t in (\"lotka_volterra\", \"slcp\", \"gaussian_linear_uniform\", \"two_moons\"):\n",
    "        for ns in (\n",
    "            (100,)*10, (1000,)*10, (10000,)*10,\n",
    "        ):\n",
    "            for no in range(1,10):\n",
    "                for random_seed in (1,2,3):\n",
    "                    print(t, ns, no, random_seed)\n",
    "                    try:\n",
    "                        result = r.fetch_one_result(\n",
    "                            experience_name=\"sunle\",\n",
    "                            task=t,\n",
    "                            random_seed=random_seed,\n",
    "                            num_observation=no,\n",
    "                            num_samples=ns,\n",
    "\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "                    rs[(t, ns, no)] = {}\n",
    "                    rs[(t, ns, no)] = {\n",
    "                        'training':   sum(r.train_results.time for r in result.result.train_results.single_round_results),\n",
    "                        'simulation': sum(r.simulation_time for r in result.result.train_results.single_round_results),\n",
    "                        'inference':   sum(r.inference_time for r in result.result.train_results.single_round_results)\n",
    "                    }\n",
    "    df = pd.DataFrame(rs).T\n",
    "    df.index.names = [\"task\", \"num_simulations\", \"num_observation\"]\n",
    "    df = df.reset_index()\n",
    "    df['algorithm'] = ['AUNLE' if len(ns) == 1 else 'SUNLE' for ns in df.num_simulations.values]\n",
    "    df['num_simulations'] = [sum(ns) for ns in df.num_simulations.values]\n",
    "    df = df.set_index([c for c in df.columns.values if c not in (\"simulation\", \"inference\", \"training\")])\n",
    "    df[['training', 'inference', 'simulation']] = df[['training', 'inference', 'simulation']] / 60\n",
    "    \n",
    "    df_sunle_time = df\n",
    "    if save_res:\n",
    "        with open(\"df_time_sunle_cached.pkl\", \"wb\") as f:\n",
    "            pickle.dump(df_sunle_time, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4c2482-22aa-494c-adfe-4df301c92e12",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AUNLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c612b8-f805-44c1-b17f-e4114af6b424",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if load_aunle:\n",
    "    with open(\"df_aunle_cached.pkl\", \"rb\") as f:\n",
    "        df_aunle_eval = pickle.load(f)\n",
    "    with open(\"df_time_aunle_cached.pkl\", \"rb\") as f:\n",
    "        df_aunle_time = pickle.load(f)\n",
    "else:\n",
    "    r = ResultsManager(\"icml\")\n",
    "    \n",
    "    # PERFORMANCE\n",
    "    rs = []\n",
    "    for t in (\"lotka_volterra\", \"slcp\", \"gaussian_linear_uniform\", \"two_moons\"):\n",
    "        print(t)\n",
    "        eval_result = r.fetch_evaluation_results(\n",
    "            experience_name=\"aunle\",\n",
    "            task=t\n",
    "        )\n",
    "        rs.append(eval_result)\n",
    "    df_aunle_eval = pd.concat(rs)\n",
    "    if save_res:\n",
    "        with open(\"df_aunle_cached.pkl\", \"wb\") as f:\n",
    "            pickle.dump(df_aunle_eval, f)\n",
    "            \n",
    "    # TIME\n",
    "    rs = {}\n",
    "    for t in (\"lotka_volterra\", \"slcp\", \"gaussian_linear_uniform\", \"two_moons\"):\n",
    "        for ns in (\n",
    "            (1000,), (10000,), (100000,),\n",
    "        ):\n",
    "            for no in range(1,10):\n",
    "                for random_seed in (1,2,3):\n",
    "                    print(t, ns, no, random_seed)\n",
    "                    try:\n",
    "                        result = r.fetch_one_result(\n",
    "                            experience_name=\"aunle\",\n",
    "                            task=t,\n",
    "                            random_seed=random_seed,\n",
    "                            num_observation=no,\n",
    "                            num_samples=ns,\n",
    "\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "\n",
    "                    rs[(t, ns, no)] = {}\n",
    "                    rs[(t, ns, no)] = {\n",
    "                        'training':   sum(r.train_results.time for r in result.result.train_results.single_round_results),\n",
    "                        'simulation': sum(r.simulation_time for r in result.result.train_results.single_round_results),\n",
    "                        'inference':   sum(r.inference_time for r in result.result.train_results.single_round_results)\n",
    "                    }\n",
    "    df = pd.DataFrame(rs).T\n",
    "    df.index.names = [\"task\", \"num_simulations\", \"num_observation\"]\n",
    "    df = df.reset_index()\n",
    "    df['algorithm'] = ['AUNLE' if len(ns) == 1 else 'SUNLE' for ns in df.num_simulations.values]\n",
    "    df['num_simulations'] = [sum(ns) for ns in df.num_simulations.values]\n",
    "    df = df.set_index([c for c in df.columns.values if c not in (\"simulation\", \"inference\", \"training\")])\n",
    "    df[['training', 'inference', 'simulation']] = df[['training', 'inference', 'simulation']] / 60\n",
    "    \n",
    "    df_aunle_time = df\n",
    "    if save_res:\n",
    "        with open(\"df_time_aunle_cached.pkl\", \"wb\") as f:\n",
    "            pickle.dump(df_aunle_time, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0100cc0-aa4a-4154-8cca-8e43859f2e61",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SMNLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c94a60-1816-4ac9-8489-14619c258c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_sm.pkl', 'rb') as f:\n",
    "    smnle_results_ssm= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a75f3a-52c9-4a64-959f-acb6eb0deca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "smnle_results_ssm = dict(smnle_results_ssm)\n",
    "df_ssm_eval = pd.concat(\n",
    "    {k: pd.DataFrame(v[0]) for k, v in smnle_results_ssm.items()},\n",
    "    names=(\"algorithm\", \"task\", \"num_observation\", \"lr\", \"num_samples\")\n",
    ")\n",
    "df_ssm_time = pd.concat(\n",
    "    {k: pd.DataFrame(v[1], index=[0]) for k, v in smnle_results_ssm.items()},\n",
    "    names=(\"algorithm\", \"task\", \"num_observation\", \"lr\", \"num_samples\")\n",
    ")\n",
    "\n",
    "df_ssm_time = df_ssm_time.unstack(level=-1).sum(axis=1).to_frame('RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c21fb00-9424-4906-98c4-00a5ed4fefbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_ssm_eval.unstack(level='algorithm').stack(level=0).rename(columns={'SM': 'SMNLE(SM)', 'SSM': 'SMNLE(SSM)'}).stack().unstack(level=-2).swaplevel(-2, -1).swaplevel(-3, -2).swaplevel(-4, -3).swaplevel(-5, -4).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c654748-3b7a-4d44-985b-205f09d8f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = df.index.set_names(\"num_simulations\",level=\"num_samples\")\n",
    "df.index = df.index.set_levels([\"10³\", \"10⁴\", \"10⁵\"] ,level=\"num_simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400e070b-d85b-4902-a3c0-d4b6fbdc63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_results = df.groupby([\"task\", \"num_simulations\", \"algorithm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda5a87-4473-469e-b3cb-6fc9a6b7d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gs = []\n",
    "for n, g in avg_results:\n",
    "    mean_per_lr = g.mmd.groupby(level=\"lr\").mean()\n",
    "    best_lr = mean_per_lr.index[mean_per_lr.argmin()]\n",
    "    new_g = g.xs(best_lr, level=\"lr\", drop_level=False)\n",
    "    new_gs.append(new_g)\n",
    "    \n",
    "best_results = pd.concat(new_gs)\n",
    "best_results = best_results.rename(columns={\"c2st\": \"C2ST\", \"mmd\": \"MMD\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fec76-f051-4ab3-99be-5ce6783c0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results_mean = best_results.groupby([\"task\", \"num_simulations\", \"algorithm\"]).mean()\n",
    "best_results_std = best_results.groupby([\"task\", \"num_simulations\", \"algorithm\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c84a8f-5ac0-49b5-9e1e-ad6a03f76424",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_smnle_results = best_results.copy()\n",
    "best_smnle_results['num_rounds'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80f0e5e-29a4-498b-9243-6ad096df809a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3ee69-1483-46fb-934b-13cc0a2a30f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(eres):\n",
    "    num_unique_fields = eres.reset_index().apply(lambda x: len(x.unique()))\n",
    "    nonunique_fields = list(num_unique_fields[num_unique_fields > 1].index.values)\n",
    "    if set(nonunique_fields).issubset(set(['num_samples', 'num_observation', 'mmd', 'c2st', 'random_seed', 'learning_rate', 'task', 'max_iter'])):\n",
    "        return eres.reset_index()[nonunique_fields]\n",
    "    else:\n",
    "        nonunique_fields = nonunique_fields.remove('max_iter')\n",
    "        return eres.reset_index().drop(columns='max_iter')[nonunique_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c3ee5-f773-4055-ae77-094c23ef64b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_unique_fielded_df(df, ebm_model_type, task=None):\n",
    "    df = df.copy()\n",
    "    \n",
    "    if ebm_model_type == \"likelihood\":\n",
    "        df['algorithm'] = \"SUNLE\"\n",
    "    else:\n",
    "        assert ebm_model_type == \"joint_tilted\"\n",
    "        df['algorithm'] = \"AUNLE\"\n",
    "        \n",
    "    if task is not None:\n",
    "        df['task'] = task\n",
    "        \n",
    "    num_simulations_str_map = {100000: \"10⁵\", 10000: \"10⁴\", 1000: \"10³\"}\n",
    "    \n",
    "    \n",
    "    df['num_simulations'] = df.num_samples.apply(lambda x: num_simulations_str_map[sum(x)])\n",
    "    df['num_rounds'] = df.num_samples.apply(len)\n",
    "    \n",
    "    df = df.drop(\"num_samples\", axis=1)\n",
    "    \n",
    "    df = df.rename(columns={\"c2st\": \"C2ST\", \"mmd\": \"MMD\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c6579f-c60d-46b5-847d-5c8163566d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_res = pd.concat(\n",
    "    [format_unique_fielded_df(get_metadata(df_aunle_eval), \"joint_tilted\"), format_unique_fielded_df(get_metadata(df_sunle_eval), \"likelihood\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25660ac4-b897-4ab7-90d5-441916c3eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbibm_results = get_results()\n",
    "sbibm_results['num_rounds'] = [10 if m in (\"SNRE\", \"SNPE\", \"SNLE\") else 1 for m in sbibm_results.algorithm.values]\n",
    "sbibm_results_mini = sbibm_results[['task', 'num_simulations', \"num_rounds\", 'algorithm', 'num_observation', 'MMD', 'C2ST']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e408648-c6aa-4c75-aaef-957fff621078",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat([sbibm_results_mini, all_res], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c59a40-ff4c-418a-8b6c-848a22d5c269",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = pd.concat(\n",
    "    [all_results, best_smnle_results.reset_index().drop('lr', axis=1)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0eff623-b88f-4d84-bad9-d67bb303e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results.algorithm.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0fa77e-71fd-403e-bd38-41c9b664694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = all_results.set_index([c for c in all_results.columns if c not in (\"MMD\", \"C2ST\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4170c739-ac24-4610-94e2-866addb41dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f13b4d-fba4-4af7-adb1-f06d0f9333f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretty_names = {\n",
    "    \"two_moons\": \"Two Moons\",\n",
    "    \"slcp\": \"SLCP\",\n",
    "    \"gaussian_linear_uniform\": \"Gaussian Linear Uniform\",\n",
    "    \"lotka_volterra\": \"Lotka Volterra\"\n",
    "}\n",
    "metric = \"C2ST\"\n",
    "limits_metric = {\n",
    "    \"MMD\": (0, 1),\n",
    "    \"C2ST\": (0.5, 1.1)\n",
    "}\n",
    "\n",
    "errorbar_kws = dict(\n",
    "    linewidth=4,\n",
    "    elinewidth=3,\n",
    "    markersize=12,\n",
    "    capsize=7, \n",
    "    marker=\"o\"\n",
    ")\n",
    "\n",
    "\n",
    "fontsize=26\n",
    "tk_fontsize=20\n",
    "time_fontsize=20\n",
    "\n",
    "with mpl.rc_context(fname='.matplotlibrc'):\n",
    "    mpl.rc('font',family='DejaVu Sans')\n",
    "    mpl.rc(\"text\", usetex=False)\n",
    "\n",
    "    tasks = (\"two_moons\", \"slcp\", \"lotka_volterra\", \"gaussian_linear_uniform\")\n",
    "    nrows = 2\n",
    "    f, axss = plt.subplots(ncols=len(tasks), nrows=nrows, figsize=(6 * len(tasks), 3.5 * nrows))\n",
    "    \n",
    "    axs = axss[0]\n",
    "        \n",
    "    for t_no, task in enumerate(tasks):\n",
    "        ax = axs[t_no]\n",
    "        ax.grid(axis=\"y\")\n",
    "        for axis in ['bottom','left']:\n",
    "            ax.spines[axis].set_linewidth(4)\n",
    "            \n",
    "        ax.errorbar(\n",
    "            ar.xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "            ar.xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean(),\n",
    "            ar.xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].std(),\n",
    "            label=\"A-UNLE \\n(Ours)\",\n",
    "            color=\"firebrick\",\n",
    "            **errorbar_kws\n",
    "        )\n",
    "\n",
    "\n",
    "        ax.errorbar(\n",
    "            ar.xs(task, level=\"task\").xs(\"SMNLE(SSM)\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "            ar.xs(task, level=\"task\").xs(\"SMNLE(SSM)\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean(),\n",
    "            ar.xs(task, level=\"task\").xs(\"SMNLE(SSM)\", level=\"algorithm\").groupby(\"num_simulations\")[metric].std(),\n",
    "            label=\"SMNLE\",\n",
    "            color=\"goldenrod\",\n",
    "            **errorbar_kws\n",
    "        )\n",
    "\n",
    "        ax.set_ylim(*limits_metric[metric])\n",
    "        ax.errorbar(\n",
    "            ar.xs(task, level=\"task\").xs(\"NLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "            ar.xs(task, level=\"task\").xs(\"NLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean(),\n",
    "            ar.xs(task, level=\"task\").xs(\"NLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].std(),\n",
    "            label=\"NLE\",\n",
    "            color=\"royalblue\",\n",
    "            **errorbar_kws\n",
    "        )\n",
    "\n",
    "\n",
    "        ax.set_ylim(*limits_metric[metric])\n",
    "\n",
    "\n",
    "        ax.set_title(pretty_names[task], fontsize=fontsize, pad=20)\n",
    "        ax.tick_params(axis='both', labelsize=tk_fontsize)\n",
    "        ax.get_xaxis().set_ticks([])\n",
    "        \n",
    "        import seaborn as sns\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            snle_rt = sbr['RT'].xs(task, level=\"task\").xs(\"NLE\", level=\"algorithm\").mean()\n",
    "            aunle_rt = df_aunle_time.sum(axis=1).to_frame(\"RT\").xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").mean()[0]\n",
    "            sunle_rt = df_sunle_time.sum(axis=1).to_frame(\"RT\").xs(task, level=\"task\").xs(\"SUNLE\", level=\"algorithm\").mean()[0]\n",
    "            smnle_rt = df_ssm_time['RT'].xs(task, level=\"task\").xs(\"SSM\", level=\"algorithm\").mean()\n",
    "            max_rt = max(snle_rt, sunle_rt)\n",
    "            total_max_rt = 50\n",
    "\n",
    "            divider = make_axes_locatable(ax)\n",
    "            ax1 = divider.append_axes('right', size='10%', pad=0.3)\n",
    "            ax1.set_xlim(0,2)\n",
    "\n",
    "            ax1.set_ylim(0, total_max_rt + 5)\n",
    "\n",
    "            ticks = np.arange(0, total_max_rt + 5, 5)\n",
    "            ax1.set_yticks(ticks)\n",
    "            ax1.set_yticklabels([\"0\"] + [\"\"]*len(ticks[1:-1]) + [str(int(ticks[-1]))], fontsize=time_fontsize)\n",
    "            ax1.set_xticks([])\n",
    "\n",
    "            ax1.eventplot(positions = np.array([snle_rt, sunle_rt, smnle_rt]).reshape(-1,1), linewidths=8, lineoffsets=[1,1,1,1,1][:3], colors=[\"royalblue\", \"firebrick\", 'goldenrod', \"#984ea3\", \"#4daf4a\",\"#e41a1c\"][:3], linelengths=2, orientation='vertical')\n",
    "\n",
    "            ax1.set_ylabel(\"time [m] \",  fontsize=time_fontsize, labelpad=-20)\n",
    "\n",
    "            ax1.yaxis.tick_right()\n",
    "            ax1.yaxis.set_label_position(\"right\")\n",
    "            ax1.yaxis.set_tick_params(length=0,labelbottom=False)\n",
    "            plt.subplots_adjust(wspace=0.5, hspace=0.8)\n",
    "\n",
    "        \n",
    "    l = axs[0].legend(fontsize=fontsize, bbox_to_anchor=(-0.2, 0.5), bbox_transform=axs[0].transAxes, loc=\"center right\")\n",
    "    axs[0].set_ylabel(\"C2ST\", size=20)\n",
    "    l.texts[0].set_weight(\"bold\")\n",
    "    \n",
    "    axs = axss[1]\n",
    "        \n",
    "    for t_no, task in enumerate(tasks):\n",
    "        ax = axs[t_no]\n",
    "        ax.grid(axis=\"y\")\n",
    "        for axis in ['bottom','left']:\n",
    "            ax.spines[axis].set_linewidth(4)\n",
    "            \n",
    "        ax.errorbar(\n",
    "            ar.xs(task, level=\"task\").xs(\"SUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "            ar.xs(task, level=\"task\").xs(\"SUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean(),\n",
    "            ar.xs(task, level=\"task\").xs(\"SUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].std(),\n",
    "            label=\"S-UNLE \\n(Ours)\",\n",
    "            color=\"firebrick\",\n",
    "            **errorbar_kws\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        ax.set_ylim(*limits_metric[metric])\n",
    "        ax.errorbar(\n",
    "            ar.xs(task, level=\"task\").xs(\"SNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "            ar.xs(task, level=\"task\").xs(\"SNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean(),\n",
    "            ar.xs(task, level=\"task\").xs(\"SNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].std(),\n",
    "            label=\"SNLE\",\n",
    "            color=\"royalblue\",\n",
    "            **errorbar_kws\n",
    "        )\n",
    "\n",
    "\n",
    "        ax.set_ylim(*limits_metric[metric])\n",
    "\n",
    "        ax.tick_params(axis='both', labelsize=tk_fontsize)\n",
    "        \n",
    "        ax.get_xaxis().set_ticklabels(\n",
    "            ar.xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "        )\n",
    "        ax.set_xlabel(\"Num. Simulations\", size=20)\n",
    "        \n",
    "        ax.get_xaxis().set_ticklabels(\n",
    "            ar.xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").groupby(\"num_simulations\")[metric].mean().index,\n",
    "        )\n",
    "        \n",
    "        import seaborn as sns\n",
    "        with sns.axes_style(\"whitegrid\"):\n",
    "            snle_rt = sbr['RT'].xs(task, level=\"task\").xs(\"SNLE\", level=\"algorithm\").mean()\n",
    "            aunle_rt = df_aunle_time.sum(axis=1).to_frame(\"RT\").xs(task, level=\"task\").xs(\"AUNLE\", level=\"algorithm\").mean()[0]\n",
    "            sunle_rt = df_sunle_time.sum(axis=1).to_frame(\"RT\").xs(task, level=\"task\").xs(\"SUNLE\", level=\"algorithm\").mean()[0]\n",
    "            max_rt = max(snle_rt, sunle_rt)\n",
    "            total_max_rt = 50\n",
    "\n",
    "            divider = make_axes_locatable(ax)\n",
    "            ax1 = divider.append_axes('right', size='10%', pad=0.3)\n",
    "            ax1.set_xlim(0,2)\n",
    "\n",
    "            ax1.set_ylim(0, total_max_rt + 5)\n",
    "\n",
    "            ticks = np.arange(0, total_max_rt + 5, 5)\n",
    "            ax1.set_yticks(ticks)\n",
    "            ax1.set_yticklabels([\"0\"] + [\"\"]*len(ticks[1:-1]) + [str(int(ticks[-1]))], fontsize=time_fontsize)\n",
    "\n",
    "            ax1.set_xticks([])\n",
    "\n",
    "            ax1.eventplot(positions = np.array([snle_rt, sunle_rt]).reshape(-1,1), linewidths=8, lineoffsets=[1,1,1,1,1][:2], colors=[\"royalblue\", \"firebrick\", \"#984ea3\", \"#4daf4a\",\"#e41a1c\"][:2], linelengths=2, orientation='vertical')\n",
    "\n",
    "            ax1.set_ylabel(\"time [m] \",  fontsize=time_fontsize, labelpad=-20)\n",
    "\n",
    "            ax1.yaxis.tick_right()\n",
    "            ax1.yaxis.set_label_position(\"right\")\n",
    "            ax1.yaxis.set_tick_params(length=0,labelbottom=False)\n",
    "            plt.subplots_adjust(wspace=0.5, hspace=0.8)\n",
    "\n",
    "        \n",
    "    l = axs[1].legend(fontsize=fontsize, bbox_to_anchor=(-0.2, 0.5), bbox_transform=axs[0].transAxes, loc=\"center right\")\n",
    "    axs[0].set_ylabel(\"C2ST\", size=20)\n",
    "    l.texts[0].set_weight(\"bold\")\n",
    "\n",
    "f\n",
    "f.savefig(\"figure-2.pdf\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5560c51b-3423-47ad-939a-c4192fa8c067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
